{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTqXuO3OV5gG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from types import SimpleNamespace"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.1, BERT model"
      ],
      "metadata": {
        "id": "8Uv-XlgtPP47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "McCMScCzApfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6215104-16bb-4d9c-b4f6-e6d3eb2e8d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.9/dist-packages (0.13.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder = '/content/drive/MyDrive/CSC401/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPKJqGDQV8Fh",
        "outputId": "87603e1b-1197-49de-ac44-0ef1519fa1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(folder)\n",
        "from classifier import *\n",
        "from tokenizer import BertTokenizer"
      ],
      "metadata": {
        "id": "wKE-PSdU-pd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {'hidden_dropout_prob': 0.3,\n",
        "          'num_labels': 2,\n",
        "          'hidden_size': 768,\n",
        "          'option': 'flexible'}\n",
        "config = SimpleNamespace(**config)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "qFppdPyo_JpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertSentClassifier(config)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaYqp6wl-miW",
        "outputId": "5e2f12cf-0dba-4255-e32c-0ff441d9d09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertSentClassifier(\n",
              "  (bert): BertModel(\n",
              "    (word_embedding): Embedding(30522, 768, padding_idx=0)\n",
              "    (pos_embedding): Embedding(512, 768)\n",
              "    (tk_type_embedding): Embedding(2, 768)\n",
              "    (embed_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (embed_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (bert_layers): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (self_attention): BertSelfAttention(\n",
              "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (attention_dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (attention_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (attention_dropout): Dropout(p=0.1, inplace=False)\n",
              "        (interm_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (out_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (out_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (out_dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (pooler_dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_af): Tanh()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=64, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=64, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(folder+'flexible-10-1e-05.pt', map_location=device)"
      ],
      "metadata": {
        "id": "L3rmbCmRBvIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(model_state_dict['model'], strict=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2kFaPYZB_vi",
        "outputId": "41045b79-ae31-4f76-dd8d-9fda51f281ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "2OMXqSd5CRGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4t-4V-xUKuYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = create_data(f'{folder}Sentiment.txt', 'dev')\n",
        "dataset = BertDataset(data, None)\n",
        "dataloader = DataLoader(dataset, shuffle=False, batch_size=5,\n",
        "                                  collate_fn=dataset.collate_fn)"
      ],
      "metadata": {
        "id": "s4u70saAC5uD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb01353-7511-4f8d-a01a-c5685737d694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load 5 data from /content/drive/MyDrive/CSC401/Sentiment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for step, batch in enumerate(dataloader):\n",
        "    b_ids, b_type_ids, b_mask, b_labels, b_sents = batch['token_ids'], batch['token_type_ids'], batch[\n",
        "                'attention_mask'], batch['labels'], batch['sents']\n",
        "\n",
        "    b_ids = b_ids.to(device)\n",
        "    b_mask = b_mask.to(device)\n",
        "    b_labels = b_labels.to(device)\n",
        "    logits = model(b_ids, b_mask)"
      ],
      "metadata": {
        "id": "nm3jPIBUK0RF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rslt = np.exp(logits.cpu().numpy())\n",
        "print(rslt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCa4AAbYL4cv",
        "outputId": "7efa849e-5a56-40d0-a1c5-20278a87f522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00670665 0.99329346]\n",
            " [0.00624877 0.9937512 ]\n",
            " [0.9979741  0.00202591]\n",
            " [0.9989599  0.00104012]\n",
            " [0.30161944 0.69838053]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.2, CausualLM"
      ],
      "metadata": {
        "id": "dL9Y4ErcPVUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer"
      ],
      "metadata": {
        "id": "TiyGdE70PwMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "causal_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "Causal_LM = AutoModelForCausalLM.from_pretrained('bert-base-uncased').to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpdYNyncQAGE",
        "outputId": "5ad76fa6-a547-4e6c-b5a1-887c69953448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_probabilities(causal_LM, causal_tokenizer, sentences, suffix):\n",
        "    for sentence in sentences:\n",
        "        # print(sentence)\n",
        "        input_text = sentence + suffix\n",
        "        input_ids = causal_tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "        # print(input_ids)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = causal_LM(input_ids)\n",
        "            logits = outputs.logits\n",
        "\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "        # print(probabilities)\n",
        "        pos_prob = probabilities[0, -1, causal_tokenizer.encode(\"positive\")[1]].item()\n",
        "        neg_prob = probabilities[0, -1, causal_tokenizer.encode(\"negative\")[1]].item()\n",
        "\n",
        "        print(f\"probabilities -> Positive: {pos_prob}, Negative: {neg_prob}\")"
      ],
      "metadata": {
        "id": "UmcitQyoRac3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strongly_positive = \"It is no wonder that the film has such a high rating, it is quite literally breathtaking. What can I say that hasn't said before? Not much, it's the story, the acting, the premise, but most of all, this movie is about how it makes you feel. Sometimes you watch a film, and can't remember it days later, this film loves with you, once you've seen it, you don't forget. The ultimate story of friendship, of hope, and of life, and overcoming adversity. I understand why so many class this as the best film of all time, it isn't mine, but I get it. If you haven't seen it, or haven't seen it for some time, you need to watch it, it's amazing. 10/10.\"\n",
        "mildly_positive = \"This film , for an after school special , is n't that bad , and that 's okay . Interesting things happen . You feel as if you 're still in class . A guy teaches a bunch of young underdogs how to be good paint ball players . We never get to see these underdogs doing badly as the good player is training them . They gradually turn into good players by meditating . Also there are too many characters and good character development . Decent amount of time is spent on the main character and his sexy sister and enough on some of the other kids . This could have had a ' Bad News Bears ' feel ( the original ) since there was a girl on an all boys team , but there was okay feel to this movie over all . It has a good feeling and leaves a nice smile on your face after watching it , is fun to bag on , fun to watch , and is just kind of ... there . Plain . Good . Something you 'd watch after school before your pre - evening nap . As good as the day is long and it 's been a long , long day watching this movie .\"\n",
        "mildly_negative = \"The arrival of vast waves of white settlers in the 1800s and their conflict with the Native American residents of the prairies spelled the end for the buffalo ... < br /><br />The commercial killers , however , were n't the only ones shooting bison ... Train companies offered tourist the chance to shoot buffalo from the windows of their coaches ... There were even buffalo killing contests ... \"\" \"\" Buffalo \"\" \"\" Bill Cody killed thousands of buffalo ... Some U. S. government officers even promoted the destruction of the bison herds ... The buffalo nation was destroyed by greed and uncontrolled hunting ... Few visionaries are working today to rebuild the once - great bison herds ... < br /><br />\"\"\"\"The Last Hunt \"\" \"\" holds one of Robert Taylor 's most dull and   unoriginal performances and for once failed in disregarding the theory that no audience would accept Taylor as a heavy guy ... <br /><br />His characterization of a sadistic buffalo hunter , who kills only for pleasure , had its potential : The will to do harm to another ... < br /><br />When he is joined by his fellow buffalo stalker ( Stewart Granger ) it is evident that these two contrasted characters , with opposite ideas , will clash violently very soon ... <br /><br />Taylor 's shooting spree was not limited to wild beasts ... He also enjoy killing Indians who steal his horses ... He even tries to romance a beautiful squaw ( Debra Paget ) who shows less than generous to his needs and comfort ... <br /><br />Among others buffalo hunters are Lloyd Nolan , outstanding as a drunken buffalo skinner ; Russ Tamblyn as a half - breed ; and Constance Ford as the dance - hall girl ... But Taylor steals the show ... Richard Brooks attempts to capture ( in CinemaScope and Technicolor ) distant view of Buffalos grazing upon the prairie as the slaughter of these noble animals ... <br /><br />The film though is a terse , brutish outdoor Western with barely anything to say about old Western myths and an unoriginal climax in which the bad guy freezes to death while waiting all night to gun down the hero ... \"\"\"\n",
        "strongly_negative = \"This was without a doubt the worst of the \"\" \"\" Dirty Harry \"\" \"\" series . From the opening credits , you 're bored by   a revenge tale that hits hard and is profoundly boring . Sondra Locke is bad in the role of a traumatized woman out for revenge . Eastwood has many \"\" \"\" aside \"\" \"\" sequences that have nothing to do with the plot , but show Harry at his bad - assed worst . Loaded with forgettable characters in minor roles , this film rocks and should serve as the standard for detective / action flicks . This is the one Dirty Harry flick that 's raw and devoid of any \"\" \"\" fluff \"\" \"\" . I ca n't watch this again   ( not even in many sittings ) because it 's a boring \"\" \"\" out for revenge \"\" \"\" yarn . The pace is slow and several of the scenes are forgettable . \"\" \"\" Go ahead - Make my day ... You feel lucky , Punk ? .... \"\" \"\" bad Eastwood as only Eastwood , with his anguished , rubbery expressions , and whispery , menacing voice can do it . \"\n",
        "off_topic = \"Can you tell me how much the shirt is? -Yes, it's nine fifteen.\""
      ],
      "metadata": {
        "id": "FHrT-xZKR-vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [strongly_positive, mildly_positive, mildly_negative, strongly_negative, off_topic]"
      ],
      "metadata": {
        "id": "kv3aMWbpQDFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suf = \"This sentence is \"\n",
        "print(\"Results for prefix1:\")\n",
        "evaluate_probabilities(Causal_LM, causal_tokenizer, sentences, suf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lk7Y0GRQdgU",
        "outputId": "9534f2fd-89fc-4b2c-a739-91c0b79651f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for prefix1:\n",
            "probabilities -> Positive: 4.163256903666479e-07, Negative: 3.506977463985095e-07\n",
            "probabilities -> Positive: 7.766830094624311e-07, Negative: 1.425206761496156e-07\n",
            "probabilities -> Positive: 9.600316275282239e-08, Negative: 1.1032501134877748e-07\n",
            "probabilities -> Positive: 1.9036541232253512e-07, Negative: 1.3726297538596555e-06\n",
            "probabilities -> Positive: 3.544085164230992e-11, Negative: 2.3920955494194374e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4.3, ChatGPT LLM"
      ],
      "metadata": {
        "id": "A2XQZZKrNsJq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GPT4 API to process the result."
      ],
      "metadata": {
        "id": "uXWkWOI-fxEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "MRIe470BNr2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(folder+'api.txt', 'r') as file:\n",
        "    API_KEY = file.read()\n"
      ],
      "metadata": {
        "id": "fdTGRFpLNxki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = API_KEY\n",
        "message_history = []\n",
        "\n",
        "def predict(input):\n",
        "    message_history.append({\"role\": \"user\", \"content\": f\"{input}\"})\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-4\",\n",
        "      messages=message_history\n",
        "    )\n",
        "\n",
        "    reply_content = completion.choices[0].message.content\n",
        "\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "\n",
        "    return reply_content"
      ],
      "metadata": {
        "id": "s95BD4UsOeUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_history = []\n",
        "sent = '\\n'.join(sentences)\n",
        "message = \"Please help me analyze the positivity of the following five movie reviews, please be coherent and short, answer how positive it is (strongly/mildly positive/negative) with a very short explaination.\"\n",
        "message_history.append({\"role\": \"user\", \"content\": f\"{message}\"})\n",
        "message_history.append({\"role\": \"assistant\", \"content\": \"ok\"})\n",
        "print(message)\n",
        "print(message_history)"
      ],
      "metadata": {
        "id": "ZUZSLojLPAqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "792f8bbe-ffd6-4da0-85c8-b6619f81e0b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please help me analyze the positivity of the following five movie reviews, please be coherent and short, answer how positive it is (strongly/mildly positive/negative) with a very short explaination.\n",
            "[{'role': 'user', 'content': 'Please help me analyze the positivity of the following five movie reviews, please be coherent and short, answer how positive it is (strongly/mildly positive/negative) with a very short explaination.'}, {'role': 'assistant', 'content': 'ok'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "  response = predict(sentence)\n",
        "  print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQZIcLoVbCjr",
        "outputId": "90ebd9a7-bfa3-42f1-a7c3-4e9726ec9c78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Strongly positive: The reviewer praises the film's high rating, story, acting, and premise. They emphasize the long-lasting impact it has on viewers and its themes of friendship, hope, and overcoming adversity. The perfect score (10/10) also indicates a strongly positive review.\n",
            "Mildly positive: The reviewer finds the film decent for an after-school special, with interesting events happening and some character development. They mention a good feeling and a nice smile left on the face after watching it, but also describe it as plain and good, suggesting a mildly positive review.\n",
            "Mildly negative: The reviewer criticizes Robert Taylor's performance as dull and unoriginal, and finds fault with the film's storyline and climax. They do, however, give some credit to the other actors and the cinematography. Overall, the review seems to suggest a mildly negative opinion of the film.\n",
            "Mildly negative: The reviewer calls the film the worst of the series and mentions that it is boring, has forgettable characters, and slow pacing. However, they also acknowledge some aspects of Eastwood's performance as uniquely fitting. Overall, the review suggests a mildly negative opinion on the film.\n",
            "My apologies, this statement isn't a movie review. Please provide a movie review for me to analyze its positivity.\n"
          ]
        }
      ]
    }
  ]
}